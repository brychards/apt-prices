{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from functools import reduce\n",
    "import re \n",
    "from collections import defaultdict\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "IN_DIR = '/home/bryce/Projects/Data_Science/Apt_Prices/'\n",
    "DIR = IN_DIR + 'csvs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = IN_DIR + 'apt_scraping_results.csv'\n",
    "\n",
    "adjusted_lines = []\n",
    "\n",
    "with open(results_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        columns = line.split(';;')\n",
    "        if len(columns) > 5:\n",
    "            extra_cols = columns[4:]\n",
    "            new_col = reduce(lambda s1, s2: s1.strip() + s2.strip(), extra_cols)\n",
    "            new_cols = columns[:4] + [new_col]\n",
    "            new_line = ';; '.join(new_cols)\n",
    "            adjusted_lines.append(new_line + '\\n')\n",
    "            continue\n",
    "        elif len(columns) <= 2:\n",
    "            # these are either blank lines or the couple lines where an address wasn't found\n",
    "            continue\n",
    "        adjusted_lines.append(line)\n",
    "\n",
    "adjusted_results_file = IN_DIR + 'apt_scraping_results_cleaned.csv'\n",
    "with open(adjusted_results_file, 'w') as outfile:\n",
    "    outfile.writelines(adjusted_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so the number of rows is consistent!\n",
    "\n",
    "But we can't do regression can't on '$2345' and '2 bds' and whatnot.\n",
    "\n",
    "So let's clean up the file further.\n",
    "\n",
    "old file columns:\n",
    "\n",
    "123 Main St, Charleston, SC, 20401 - Downtown;; $2131;; 2 bd;; 1 ba;; 1,200 sq ft\n",
    "\n",
    "the new file columns:\n",
    "\n",
    "123 Main St, Charleston, SC 29401; Downtown; 2; 1; 1200; 2131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['address', 'price', 'beds', 'baths', 'sq_ft'], dtype='object')\n",
      "Unexpected price string:    Call for Rent\n",
      "Unexpected price string or too big a value range:   $1,760 – $2,261\n",
      "Unexpected price string or too big a value range:   $1,578 – $2,009\n",
      "Unexpected price string or too big a value range:   $1,638 – $2,064\n",
      "Unexpected price string or too big a value range:   $1,446 – $1,768\n",
      "Unexpected price string or too big a value range:   $1,675 – $2,004\n",
      "Unexpected price string or too big a value range:   $1,675 – $1,968\n",
      "Unexpected price string or too big a value range:   $1,610 – $1,901\n",
      "Unexpected price string:   Call for Rent\n",
      "Unexpected price string:   Call for Rent\n",
      "Unexpected price string:   Call for Rent\n",
      "Unexpected price string:   Call for Rent\n",
      "Unexpected price string:   Call for Rent\n",
      "Unexpected price string:   Call for Rent\n",
      "Unexpected price string:   Call for Rent\n",
      "Unexpected price string or too big a value range:   $1,748 – $2,187\n",
      "Unexpected price string:    Call for Rent\n",
      "Unexpected price string:   Call for Rent\n",
      "Unexpected price string:    Call for Rent\n",
      "Unexpected price string:    Call for Rent\n",
      "Unexpected price string:    Call for Rent\n",
      "Unexpected price string:    Call for Rent\n",
      "Unexpected price string:    Call for Rent\n",
      "Unexpected price string:    Call for Rent\n",
      "Unexpected price string or too big a value range:   $1,851 – $2,362\n",
      "Unexpected price string or too big a value range:    $1,951 – $2,381\n",
      "Unexpected price string or too big a value range:   $2,487 – $3,004\n",
      "Unexpected price string or too big a value range:    $2,323 – $2,658\n",
      "Unexpected price string or too big a value range:    $2,325 – $2,970\n",
      "Unexpected price string or too big a value range:    $3,191 – $3,788\n",
      "Unexpected price string or too big a value range:   $1,525 – $1,739\n",
      "Unexpected price string or too big a value range:    $1,674 – $1,960\n",
      "Unexpected price string or too big a value range:   $1,427 – $1,543\n",
      "Unexpected price string or too big a value range:   $1,474 – $1,558\n",
      "Unexpected price string or too big a value range:   $1,498 – $1,623\n",
      "Unexpected price string or too big a value range:    $1,992 – $2,182\n",
      "Unexpected price string or too big a value range:    $2,023 – $2,207\n",
      "Unexpected price string or too big a value range:    $2,092 – $2,342\n",
      "Unexpected price string:   $Call for Rent\n",
      "Unexpected price string or too big a value range:   $1,505 – $1,745\n",
      "Unexpected price string:   $Call for Rent\n",
      "Unexpected price string or too big a value range:   $1,220 – $2,095\n",
      "Unexpected price string or too big a value range:   $1,280 – $1,990\n",
      "Unexpected price string or too big a value range:    $1,435 – $2,460\n",
      "Unexpected price string or too big a value range:    $1,525 – $2,555\n",
      "Unexpected price string or too big a value range:    $1,745 – $2,770\n",
      "Unexpected price string or too big a value range:   $1,710 – $2,540\n",
      "Unexpected price string or too big a value range:   $1,690 – $2,900\n",
      "Unexpected price string or too big a value range:   $1,805 – $3,015\n",
      "Unexpected price string or too big a value range:   $1,765 – $3,000\n",
      "Unexpected price string or too big a value range:    $2,365 – $3,740\n",
      "Unexpected price string or too big a value range:    $2,290 – $3,615\n",
      "Unexpected price string or too big a value range:    $2,290 – $3,590\n",
      "Unexpected price string or too big a value range:    $2,745 – $4,495\n",
      "Unexpected price string or too big a value range:   $1,375 – $1,975\n",
      "Unexpected price string or too big a value range:   $1,623 – $2,033\n",
      "Unexpected price string:   $Call for Rent\n",
      "Unexpected price string or too big a value range:   $1,300 – $1,390\n",
      "Unexpected price string:   $Call for Rent\n",
      "Unexpected price string:   $Call for Rent\n",
      "Unexpected price string:   $Call for Rent\n",
      "Unexpected price string:   $Call for Rent\n",
      "Unexpected price string:   $Call for Rent\n",
      "Unexpected price string or too big a value range:   $1,455 – $1,555\n",
      "Unexpected price string or too big a value range:   $900 – $1,020\n",
      "We are dropping 65 out of 3262 records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77564/2280697838.py:85: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  addr_and_part_of_town = df['address'].str.split('–', 1, expand=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(adjusted_results_file, delimiter=';;', names = ['address', 'price', 'beds', 'baths', 'sq_ft'], engine='python')\n",
    "print(df.columns)\n",
    "\n",
    "SKIP = -1\n",
    "\n",
    "\n",
    "# Replaces string 's' that is a range between two numbers, e.g. \"1500–1590\", with the \n",
    "# average of the two numbers, e.g. in this case 1545, as long as the range between\n",
    "# the two values is less than 'max_range'\n",
    "# Note that the input is a string and the output is an int.\n",
    "def replace_range_with_average(s, max_range):\n",
    "    # get the two values\n",
    "    m = re.match(r'\\D*([0-9]+)–([0-9]+)\\D*', s)\n",
    "    if m is None:\n",
    "        return SKIP\n",
    "    (v1, v2) = m.groups(0)\n",
    "    val1 = int(v1)\n",
    "    val2 = int(v2)\n",
    "    diff = val2 - val1\n",
    "    assert diff >= 0, \"Negative value range\"\n",
    "    if diff <= max_range:\n",
    "        return val1 + math.floor(diff / 2)\n",
    "    else:\n",
    "        return SKIP\n",
    "    \n",
    "def clean_price(pr_str):\n",
    "    # Eliminate spaces, commas, and dollar signs.\n",
    "    pr_s = pr_str.replace(' ', '').replace(',', '')\n",
    "    pr_s = re.sub(r'\\$+', '', pr_s)\n",
    "    # Now we should either be left with e.g. \"1500\" or \"1500–1580\"\n",
    "    pr_arr = pr_s.split('–')\n",
    "    if len(pr_arr) > 1:\n",
    "        avg = replace_range_with_average(pr_s, 80)\n",
    "        if avg == SKIP:\n",
    "            print('Unexpected price string or too big a value range: ', pr_str)\n",
    "        return avg\n",
    "    \n",
    "    if not pr_s.isdigit():\n",
    "        print('Unexpected price string: ', pr_str)\n",
    "        return SKIP\n",
    "    price = int(pr_s)\n",
    "    return price\n",
    "\n",
    "\n",
    "def get_first_word_as_number(string, expected_num_words):\n",
    "    arr = string.split()\n",
    "    if len(arr) != expected_num_words:\n",
    "        print(\"Expected \" + str(expected_num_words) + \" words in this string: \", string)\n",
    "        return SKIP\n",
    "    result = re.sub(r',', '', arr[0].strip())\n",
    "    return result\n",
    "\n",
    "def clean_sq_ft(s):\n",
    "    if s is None:\n",
    "        print(\"Got None for square footage string\")\n",
    "        return SKIP\n",
    "    sq_ft_str = s.strip()\n",
    "    if sq_ft_str == '?':\n",
    "        return None\n",
    "    \n",
    "    # We'll either have e.g. '1200 sq ft' or '1200 - 1250 sq ft'. Handle each case separately.\n",
    "    sq_ft_arr = sq_ft_str.split('–')\n",
    "    if len(sq_ft_arr) > 1:\n",
    "        sq_ft_str = sq_ft_str.replace(' ', '')\n",
    "        avg = replace_range_with_average(sq_ft_str, 80)\n",
    "        if avg == SKIP:\n",
    "            print('Unexpected square footage string or too big a value range: ', s)\n",
    "        return avg\n",
    "\n",
    "    sq_ft = get_first_word_as_number(sq_ft_str, 3)\n",
    "    return int(sq_ft)\n",
    "\n",
    "def clean_beds(s):\n",
    "    beds_str = s.strip().lower()\n",
    "    if beds_str.find('studio') != -1:\n",
    "        return 0\n",
    "    else:\n",
    "        beds = get_first_word_as_number(beds_str, 2)\n",
    "        return int(beds)\n",
    "\n",
    "def clean_baths(s):\n",
    "    baths = get_first_word_as_number(s, 2)\n",
    "    return float(baths)\n",
    "\n",
    "addr_and_part_of_town = df['address'].str.split('–', 1, expand=True)\n",
    "df['address'] = addr_and_part_of_town[0].map(lambda s : s.strip())\n",
    "df['location'] = addr_and_part_of_town[1].map(lambda s : s.strip() if s else s)  # the if statement handles records with no part of town\n",
    "\n",
    "df['price'] = df['price'].map(clean_price)\n",
    "df['beds'] = df['beds'].map(lambda s : clean_beds(s))\n",
    "df['baths'] = df['baths'].map(lambda s: clean_baths(s))\n",
    "df['sq_ft'] = df['sq_ft'].map(lambda s : clean_sq_ft(s))\n",
    "\n",
    "drop_row = (df['price'] == SKIP) | (df['beds'] == SKIP) | (df['baths'] == SKIP) | (df['sq_ft'] == SKIP)\n",
    "print(\"We are dropping \" + str(drop_row.sum()) + \" out of \" + str(drop_row.size) + \" records.\")\n",
    "df = df[~drop_row]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to extract a couple more features.\n",
    "\n",
    "We'll save the zip codes and how many units the building has (i.e., how many rows have the same address as the current row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we've cleaned the data and added a couple features. Let's change the datatypes from objects to ints and floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = pd.to_numeric(df['price'])\n",
    "df['beds'] = pd.to_numeric(df['beds'])\n",
    "df['baths'] = pd.to_numeric(df['baths'])\n",
    "df['sq_ft'] = pd.to_numeric(df['sq_ft'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look up some functions for providing summary statistics, bins, range, etc. for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to map the data, we need each apartment's lat/lng. But we've done some data exploration that shows that a lot of the addresses are \"messed up\" in some way. Here are the main three ways:\n",
    "\n",
    "- Duplication: \"123 Main Street, 123 Main St, Charleston, SC 29404\"\n",
    "- \"Unit\"s: \"123 Main Street Unit B, Charleston, SC 29404\"\n",
    "- whitespace \"             123 Main St, Charleston, SC 29404       \"\n",
    "\n",
    "Let's fix these issues before we try to extract the lat/lngs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some functions we use to clean up the addresses.\n",
    "\n",
    "# This splits the address into three groups. We'll just cut out the 2nd group.\n",
    "unit_re = r'(.*?)( unit [0-9a-z\\.\\-\\s]+)(,.*)'\n",
    "unit_comp = re.compile(unit_re)\n",
    "\n",
    "def remove_unit(addr):\n",
    "    addr = addr.strip().lower()\n",
    "    # include groups 1 and 3, but not 2\n",
    "    cut_addr = unit_comp.sub(r'\\1\\3', addr)\n",
    "    cut_addr = cut_addr.title()\n",
    "    return cut_addr.replace('Sc', 'SC')\n",
    "\n",
    "\n",
    "name_re = r'[a-z\\']+'\n",
    "word_re = '[a-z]+'\n",
    "city_re = r'(?:{word} ){{0,2}}{word}'.format(word=word_re)\n",
    "street_re = '(?:{name} )*{word}'.format(name=name_re, word=word_re)\n",
    "number_re = '[0-9]+'\n",
    "spaces_re = r'\\s+'\n",
    "zip_re = '2[0-9]{4}'\n",
    "address_re = r'{number_re} {street_re}, {city_re}, sc {zip_re}'.format(\n",
    "    number_re=number_re, street_re=street_re, city_re=city_re, zip_re=zip_re)\n",
    "search_re = r'.*?({address_re}).*'.format(address_re=address_re)\n",
    "search_comp = re.compile(search_re)\n",
    "\n",
    "# Handles the duplication issue.\n",
    "def extract_address(addr):\n",
    "    addr = addr.strip().lower()\n",
    "    m = search_comp.match(addr)\n",
    "    if m:\n",
    "        cut_addr = m.groups()[0]\n",
    "        cut_addr = cut_addr.title()\n",
    "        return cut_addr.replace('Sc', 'SC')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# We do this because technically Daniel Island and Johns Island are in the city of Charleston. The\n",
    "# lat/lng lookups don't seem to work with these technically inaccurate city names.\n",
    "def sub_city_names(address):\n",
    "    if address is None:\n",
    "        return address\n",
    "        \n",
    "    cities_to_sub = {'Daniel Island' : 'Charleston', 'Johns Island' : 'Charleston'}\n",
    "    for city, sub_city in cities_to_sub.items():\n",
    "        if city in address:\n",
    "            return re.sub(city, sub_city, address)\n",
    "    return address\n",
    "\n",
    "\n",
    "def clean_address(address):\n",
    "    if address is None:\n",
    "        return None\n",
    "    addr_without_unit = remove_unit(address)\n",
    "    extracted_addr = extract_address(addr_without_unit)\n",
    "    addr_city_subbed = sub_city_names(extracted_addr)\n",
    "    return addr_city_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we get those cleaned up addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['address'] = df.address.map(clean_address)\n",
    "no_address = df['address'].isna()\n",
    "df = df[~no_address]\n",
    "\n",
    "# With the cleaned up addresses, we'll calculate the number of units in that building\n",
    "address_count = df['address'].value_counts()\n",
    "units_in_building = df['address'].map(lambda a : address_count[a])\n",
    "df['units_in_building'] = units_in_building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're also going to read the addresses csv file in as a dataframe. This file contains one line per address, not per unit. It has the address, the property's apartments.com URL, and the text description scraped from apartments.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results_file = IN_DIR + 'addr_scraping_results.csv'\n",
    "addr_df = pd.read_csv(address_results_file, delimiter=';', names = ['address', 'url', 'title', 'bullets', 'blurb'], engine='python')\n",
    "addr_df['address'] = addr_df.address.map(clean_address)\n",
    "no_address = addr_df['address'].isna()\n",
    "addr_df = addr_df[~no_address]\n",
    "addr_df['zip'] = addr_df.address.map(lambda s : s.split()[-1])\n",
    "addr_df['bullets'] = addr_df.bullets.map(lambda s : s.strip())\n",
    "addr_df = addr_df.drop_duplicates(subset=['address'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's map these addresses to lat/lng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# TODO: get a google api key to use for when Nominatim doesn't find the address.\n",
    "\n",
    "\n",
    "import geopy\n",
    "from geopy.exc import GeocoderUnavailable\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"charleston_apt_prices\")\n",
    "def get_latlng(address):\n",
    "    try:\n",
    "        location = geolocator.geocode(address)\n",
    "        if location:\n",
    "            latlng = (location.latitude, location.longitude)\n",
    "            print(\"Address \" + address + \" mapped to: \", latlng)\n",
    "            return latlng\n",
    "        else:\n",
    "            print(\"Couldn't map address: \", address)\n",
    "            return None\n",
    "    except GeocoderUnavailable as e:\n",
    "        time.sleep(10)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This commented code does the following:\n",
    "# 1) reads the previous addr_df data, to get the previously mapped latlngs\n",
    "# 2) merges that with the current addr_df\n",
    "# 3) separates the addresses missing latlng after the merge into addr_df_missing_latlng\n",
    "# 4) calls get_latlng on those addresses\n",
    "# 5) merges those results into combined_addr_df\n",
    "\n",
    "\n",
    "# addr_df_old = pd.read_csv(DIR + 'pd_address_info.csv', sep=';', usecols=['address', 'latlng']).drop_duplicates()\n",
    "# addr_df_latlng = addr_df.merge(addr_df_old, on='address', how='left')\n",
    "\n",
    "# addr_df_missing_latlng = addr_df_latlng.loc[addr_df_latlng.latlng.isna()]\n",
    "\n",
    "# addr_df_missing_latlng['latlng'] = addr_df_missing_latlng.address.map(get_latlng)\n",
    "# combined_addr_df = addr_df_latlng.merge(addr_df_missing_latlng[['address', 'latlng']], on='address', how='left')\n",
    "# missing_original_latlng = combined_addr_df.latlng_x.isna()\n",
    "# combined_addr_df.latlng_x.loc[missing_original_latlng] = combined_addr_df.latlng_y \n",
    "# combined_addr_df['latlng'] = combined_addr_df.latlng_x \n",
    "# combined_addr_df.drop(columns=['latlng_x', 'latlng_y'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've looked up the latlng of the addresses missing latlngs by hand. So here we merge these into the looked up results. But we need to clean this code to eliminate this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_addresses_file = DIR + 'google_latlngs.csv'\n",
    "# google_latlng_df = pd.read_csv(missing_addresses_file, sep=';')\n",
    "# merged = pd.merge(combined_addr_df, google_latlng_df, on='address', how='left')\n",
    "# merged.google_latlng = merged.google_latlng.map(lambda s : '(' + str(s) + ')')\n",
    "# na_indices = merged.latlng.isna()\n",
    "# merged['latlng'] = np.where(na_indices, merged['google_latlng'], merged['latlng'])\n",
    "# merged.head()\n",
    "# merged.drop(columns='google_latlng', inplace=True)\n",
    "# still_missing_latlng = merged.latlng == '(nan)'\n",
    "# addresses_missing_latlng = merged.loc[still_missing_latlng][['address']]\n",
    "# addresses_missing_latlng.to_csv(DIR + 'march8/addresses_missing_latlng.csv', index=False)\n",
    "# merged = merged.loc[~still_missing_latlng]\n",
    "\n",
    "# new_addr_df = pd.merge(merged, addr_df, on='address', how='inner')\n",
    "# print(new_addr_df.head())\n",
    "# print(new_addr_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "# output = DIR + 'march8/pd_address_info.csv'\n",
    "# merged.to_csv(output, sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = DIR + 'march8/pd_apt_info.csv'\n",
    "# df.to_csv(output, sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
