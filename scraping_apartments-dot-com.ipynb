{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to need one more function to tell if we should keep clicking next page.\n",
    "\n",
    "Look at all the li -> a's in the nav bar at the botton. Find the next to last one (meaning the last number before the right arrow). If its title contains \"Next page\", you're done clicking. Otherwise, keep clicking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42270/831211215.py:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/home/bryce/Downloads/chromedriver', options=opts)\n"
     ]
    }
   ],
   "source": [
    "opts = Options()\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "opts.add_argument(\"user-agent=\" + user_agent)\n",
    "driver = webdriver.Chrome('/home/bryce/Downloads/chromedriver', options=opts)\n",
    "# This url is just the map of the charleston area. It's zoomed out and positioned so that it captures pretty much all apts in the Charleston/N. Charleston/Mt. P/James Island/Johns Island area,\n",
    "# but excludes most of Summerville and beyond. Summerville seems like an entirely different market, so I think it makes sense to exclude it.\n",
    "apt_url = 'https://www.apartments.com/?bb=56oym0-ppH44p590b'\n",
    "#apt_url = \"https://www.apartments.com/charleston-sc/\"\n",
    "#apt_url = \"https://www.apartments.com/2030-wildts-battery-blvd-johns-island-sc-unit-33847624/ks54vsb/\"\n",
    "driver.maximize_window()\n",
    "driver.get(apt_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "def click_on_element(driver, element):\n",
    "    sleep(randint(1,4))\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(element)\n",
    "    actions.move_by_offset(randint(2, 10), randint(2,10))\n",
    "    actions.pause(2)\n",
    "    actions.click()\n",
    "    actions.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each apartment, we will write its info in this format:\n",
    "PRINT_STR = \"{addr};; ${rent};; {beds} bd;; {baths} ba;; {sqft} sq ft\\n\"\n",
    "PRICING_GRID_ITEM = \"pricingGridItem\"\n",
    "SCREEN_READER_ONLY = \"screenReaderOnly\"\n",
    "\n",
    "def get_address_string(soup):\n",
    "    address_divs = soup.find_all(\"div\", class_=\"propertyAddressContainer\")\n",
    "    if (len(address_divs) == 0) :\n",
    "        print(\"COULD NOT FIND ADDRESS\")\n",
    "        return \"UNKNOWN ADDRESS\"\n",
    "    addr_string = \" \".join(address_divs[0].text.split())\n",
    "\n",
    "    # Some properties have a property name like \"The Meadows\". In these properties, the addr_string contains the street address.\n",
    "    # For single houses and such, the property name is the street address, and the addr_string will be missing it.\n",
    "    property_name_split = soup.find(\"h1\", class_=\"propertyName\").text.split()\n",
    "    if len(property_name_split) == 0:\n",
    "        print(\"WARNING: no property name found.\")\n",
    "        return addr_string\n",
    "    # If the property name starts with a number, we'll assume it's an address.\n",
    "    first_word = property_name_split[0]\n",
    "    NUMBERS_DASH_OR_DOT = r'(\\d+)(?:[\\-\\.]\\d+)?'\n",
    "    m = re.match(NUMBERS_DASH_OR_DOT, first_word)\n",
    "    if m:\n",
    "        property_name_split[0] = m.groups()[0]  # replace \"43-45 Meeting St\" with \"43 Meeting St\" for better latlng lookup\n",
    "        street_address = \" \".join(property_name_split)\n",
    "        addr_string = street_address + \", \" + addr_string\n",
    "\n",
    "    return addr_string\n",
    "\n",
    "def is_single_unit_listing(soup):\n",
    "    # Does this page have a div of class \"pricingGridItem\"? If so, return false. If not, true\n",
    "    pricing_grid_items = soup.find_all(\"div\", class_=PRICING_GRID_ITEM)\n",
    "    if (pricing_grid_items):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def save_info_from_single_unit_listing(soup, outfile):\n",
    "    address = get_address_string(soup)\n",
    "    rent_details = soup.find_all(\"p\", class_=\"rentInfoDetail\")\n",
    "    printstr = address + \";; \" + \";; \".join(map(lambda rd : rd.string if rd.string else \"?\", rent_details)) + \"\\n\"\n",
    "    outfile.write(printstr)\n",
    "\n",
    "\"\"\" Some multi-unit listings have an exact price row for every\n",
    "unit that's available. Otherse just have a price range for each floor plan.\n",
    "This function handles the latter case.\n",
    "We'll just save the price range as the price. When doing data analysis, we can\n",
    "decide how to handle these cases.\"\"\"\n",
    "def save_less_precise_info_from_multi_unit_listing(soup, address, outfile):\n",
    "    pricing_grid_items = soup.find_all(\"div\", class_=PRICING_GRID_ITEM)\n",
    "    for item in pricing_grid_items:\n",
    "        classes = item.parent[\"class\"]\n",
    "        if 'active' not in classes:\n",
    "            continue\n",
    "        rent_range = item.find(\"span\", class_=\"rentLabel\").text.strip()\n",
    "        ### print(\"rent range: \", rent_range)\n",
    "        # The first detailsTextWrapper has the bed, bath, sq ft info\n",
    "        other_info = item.find(class_=\"detailsTextWrapper\").text\n",
    "        other_info = other_info.replace(\"bed\", \"bd\").replace(\"bath\", \"ba\")\n",
    "        formatted_info = \";; \".join([w.strip() for w in other_info.split(\",\")])\n",
    "        println = \"{address};; {rent_range};; {bd_ba_sqft}\\n\".format(address=address, rent_range=rent_range, bd_ba_sqft=formatted_info)\n",
    "        outfile.write(println)\n",
    "\n",
    "\n",
    "def save_info_from_multi_unit_listing(soup, outfile):\n",
    "    #print(\"in get info from multi family listing\")\n",
    "    addr = get_address_string(soup)\n",
    "\n",
    "    pricing_grid_items = soup.find_all(\"div\", class_=PRICING_GRID_ITEM)\n",
    "    for item in pricing_grid_items:\n",
    "        classes = item.parent[\"class\"]\n",
    "\n",
    "        # This excludes not available listings and other listings that aren't shown to the user.\n",
    "        if 'active' not in classes:\n",
    "            continue\n",
    " \n",
    "        data_lis = item.find_all(\"li\", attrs={\"data-beds\" : re.compile(r'.*') })\n",
    "        \n",
    "        # Ah ha! This is one of those pages with just a price range\n",
    "        if len(data_lis) == 0:\n",
    "            save_less_precise_info_from_multi_unit_listing(soup, addr, outfile)\n",
    "            return\n",
    "\n",
    "        BEDS_ATTR = \"data-beds\"\n",
    "        BATHS_ATTR = \"data-baths\"\n",
    "        for i in range(len(data_lis)):\n",
    "            ## print(\"i: \", i)\n",
    "            li = data_lis[i]\n",
    "            # The number of beds and baths are attributes of the <li>\n",
    "            beds = li[BEDS_ATTR]\n",
    "            baths = li[BATHS_ATTR]\n",
    "\n",
    "            #Get price\n",
    "            price_column = li.find(\"div\", class_=\"pricingColumn\")\n",
    "            price_spans = price_column.find_all(\"span\")\n",
    "            assert len(price_spans) == 2, \"Expected two spans in price column\"\n",
    "            price = price_spans[1].text.strip()\n",
    "\n",
    "            \n",
    "            # Get square footage\n",
    "            sqft_column = li.find(\"div\", class_=\"sqftColumn\")\n",
    "            sqft_text = sqft_column.text\n",
    "            sqft_list = map(lambda s: s.replace(\",\", \"\"), sqft_text.split())\n",
    "            sqft_list = [s for s in sqft_list if s.isdigit()]\n",
    "            sqft = -1\n",
    "            assert len(sqft_list) == 1, \"UNEXPECTED square footage: \" + sqft_text\n",
    "            sqft = sqft_list[0]\n",
    "            printstr = PRINT_STR.format(addr=addr, rent=price, beds=beds, baths=baths, sqft=sqft)\n",
    "            outfile.write(printstr)\n",
    "\n",
    "def get_info_from_listing(driver, apartment_outfile, location_outfile):\n",
    "    #print(\"in get_info_from_listing\")\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    url = driver.current_url\n",
    "    save_per_location_info(soup, url, location_outfile)\n",
    "    if is_single_unit_listing(soup):\n",
    "        try:\n",
    "            save_info_from_single_unit_listing(soup, apartment_outfile)\n",
    "        except Exception as e:\n",
    "            print(\"Could not extract info from single-unit listing. Got Exception: \", e)\n",
    "    else:\n",
    "        try:\n",
    "            save_info_from_multi_unit_listing(soup, apartment_outfile)\n",
    "        except Exception as e:\n",
    "            print(\"Could not extract info from multi-unit listing. Got Exception: \", e)\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m amenities \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m amenities_section \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenitiesSection\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m bullet_lis \u001b[38;5;241m=\u001b[39m \u001b[43mamenities_section\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecInfo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m li \u001b[38;5;129;01min\u001b[39;00m bullet_lis:\n\u001b[1;32m      8\u001b[0m     amenity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m li\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# This way seems to work better.\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "amenities = []\n",
    "amenities_section = soup.find('section', class_='amenitiesSection')\n",
    "bullet_lis = amenities_section.find_all('li', class_='specInfo')\n",
    "for li in bullet_lis:\n",
    "    amenity = '()' + li.text.replace('\\n', '')\n",
    "    amenities.append(amenity)\n",
    "\n",
    "print(amenities)\n",
    "print(get_address_string(soup))\n",
    "\n",
    "# # This way misses some amenities. Let's see if another way will catch them all (and work for all the other cases too)\n",
    "# soup = BeautifulSoup(driver.page_source)\n",
    "# amenities = []\n",
    "# combined_amenities_uls = soup.find_all('ul', class_='combinedAmenitiesList')\n",
    "# for ul in combined_amenities_uls:\n",
    "#     bullet_lis = ul.find_all('li', class_='specInfo')\n",
    "#     for li in bullet_lis:\n",
    "#         amenity = '()' + li.text.replace('\\n', '')\n",
    "#         amenities.append(amenity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 105 Ivy Grn Wy Unit 1-1023.830916, Charleston, SC 29414 - Apartment for Rent in Charleston, SC \n"
     ]
    }
   ],
   "source": [
    "title = soup.find('title')\n",
    "title_str = title.text.replace('| Apartments.com', '')\n",
    "print(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMICOLON_REPLACEMENT = ',,,'\n",
    "NEWLINE_REPLACEMENT = '   '\n",
    "def replace_semicolons(text):\n",
    "    return text.replace(';', SEMICOLON_REPLACEMENT)\n",
    "\n",
    "def add_semicolons_back(text):\n",
    "    return text.replace(SEMICOLON_REPLACEMENT, ';')\n",
    "\n",
    "def replace_newlines(text):\n",
    "    return text.replace('\\n', NEWLINE_REPLACEMENT)\n",
    "\n",
    "def add_newlines_back(text):\n",
    "    return text.replae(NEWLINE_REPLACEMENT, '\\n')\n",
    "\n",
    "def get_combined_amenities(soup):\n",
    "    amenities = []\n",
    "    amenities_section = soup.find('section', class_='amenitiesSection')\n",
    "    if amenities_section is None:\n",
    "        return []\n",
    "    bullet_lis = amenities_section.find_all('li', class_='specInfo')\n",
    "    for li in bullet_lis:\n",
    "        amenity = '()' + li.text.replace('\\n', '')\n",
    "        amenities.append(amenity)\n",
    "        \n",
    "    return amenities \n",
    "\n",
    "def get_page_title(soup):\n",
    "    title = soup.find('title')\n",
    "    title_str = title.text.replace('| Apartments.com', '')\n",
    "    return(title_str)\n",
    "\n",
    "def get_unique_amenities(soup):\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    unique_amenity_lis = soup.find_all('li', class_='uniqueAmenity')\n",
    "    amenities = []\n",
    "    for li in unique_amenity_lis:\n",
    "        amenity = '()' + li.text.replace('\\n', '')\n",
    "        amenities.append(amenity)\n",
    "    return amenities\n",
    "\n",
    "\n",
    "def get_bullet_points(soup):\n",
    "    combined_amenities = get_combined_amenities(soup)\n",
    "    unique_amenities = get_unique_amenities(soup)\n",
    "    amenities = combined_amenities if combined_amenities else unique_amenities\n",
    "    if not combined_amenities and unique_amenities:\n",
    "        print(\"Could not find combined_amenities, but did find unique_amenities\")\n",
    "    return '. '.join(amenities) if amenities else ''\n",
    "\n",
    "def save_per_location_info(soup, url, outfile):\n",
    "    address = get_address_string(soup)\n",
    "    address_without_semis = replace_semicolons(address)\n",
    "    if (address != address_without_semis):\n",
    "        print(\"WARNING, address \" + address + \" has semicolons, for url: \", url)\n",
    "    description_section = soup.find(\"section\", class_=\"descriptionSection\")\n",
    "    blurb = ''\n",
    "    if description_section is None:\n",
    "        print ('Missing descriptionSection')\n",
    "    else:\n",
    "        ps = description_section.find_all(\"p\")\n",
    "        if ps is None:\n",
    "            print('No p tag in descriptionSection')\n",
    "        else:\n",
    "            p1 = ps[0]\n",
    "            if len(p1.attrs) > 0:\n",
    "                print(\"WARNING, first <p> of description section has attrs for url: \", url)\n",
    "            blurb = p1.text\n",
    "            if len(blurb) == 0:\n",
    "                print(\"WARNING, this page's blurb was length 0, for url \", url)\n",
    "            blurb = replace_newlines(replace_semicolons(blurb))\n",
    "    bullets = get_bullet_points(soup)\n",
    "    bullets = replace_newlines(replace_semicolons(bullets))\n",
    "    title = replace_semicolons(get_page_title(soup))\n",
    "    saveline = \"{address}; {url}; {title}; {bullets}; {blurb}\\n\".format(address=address_without_semis, url=url, title=title, bullets=bullets, blurb=blurb)\n",
    "    outfile.write(saveline)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m----> 3\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(\u001b[43mdriver\u001b[49m\u001b[38;5;241m.\u001b[39mpage_source)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_address_string(soup))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "print(get_address_string(soup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "def is_page_last(driver):\n",
    "    page_range = driver.find_element(By.CLASS_NAME, \"pageRange\")\n",
    "    page_range_text = page_range.text\n",
    "    numbers = [int(w) for w in page_range_text.split() if w.isdigit()]\n",
    "    assert len(numbers) == 2, \"We expect the page range to have two numbers in it, but apparently it doesn't: \" + page_range_text\n",
    "    return numbers[0] == numbers[1]\n",
    "\n",
    "def click_to_next_page(driver):\n",
    "    next_page_link = driver.find_element(By.CSS_SELECTOR, \"a.next\")\n",
    "    sleep(randint(3,5))\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element_with_offset(next_page_link, randint(1,10), randint(1,10))\n",
    "    actions.pause(randint(1,3))\n",
    "    actions.click()\n",
    "    actions.perform()\n",
    "\n",
    "#click_to_next_page(driver)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def save_all_results_from_page(driver, apts_outfile, addr_outfile):\n",
    "    apts_outfile.write(\"\\n\\n\")\n",
    "    sleep(random.randint(5,9))\n",
    "    count = 0\n",
    "    maxcount = 1000  # set to 1000 unless debugging\n",
    "    while True:\n",
    "        links = driver.find_elements(By.CSS_SELECTOR, \"div.item.active.us\")\n",
    "        if count >= len(links) or count > maxcount:\n",
    "            print(\"count: \", count)\n",
    "            print(\"number of links: \", len(links))\n",
    "            break\n",
    "        link = links[count]\n",
    "        click_on_element(driver, link)\n",
    "        sleep(random.random() + randint(1,2))\n",
    "        get_info_from_listing(driver, apts_outfile, addr_outfile)\n",
    "        number_appendix_map = {1 : 'st', 2 : 'nd', 3: 'rd', 11 : 'th', 12 : 'th'}\n",
    "        number_to_display = count + 1\n",
    "        appendix = number_appendix_map.get(number_to_display % 10, 'th')\n",
    "        print(\"Saved \" + str(number_to_display) + \"'\" + appendix + \" result.\")\n",
    "        driver.back()\n",
    "        sleep(random.random() + randint(1,2))\n",
    "        count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "count:  5\n",
      "number of links:  25\n"
     ]
    }
   ],
   "source": [
    "apt_outfile = open(\"/tmp/apt_results_p7.csv\", \"w\")\n",
    "addr_outfile = open(\"/tmp/addr_results_p7.csv\", \"w\")\n",
    "save_all_results_from_page(driver, apt_outfile, addr_outfile)\n",
    "apt_outfile.close()\n",
    "addr_outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_results(driver, apt_outfile, addr_outfile):\n",
    "    page = 1\n",
    "    while True:\n",
    "        print(\"About to save results from page \", page)\n",
    "        save_all_results_from_page(driver, apt_outfile, addr_outfile)\n",
    "        print(\"Finished saving page \", page)\n",
    "        if is_page_last(driver):\n",
    "            print(\"It's the last page!\")\n",
    "            break\n",
    "        print(\"Clicking to next page...\")\n",
    "        click_to_next_page(driver)\n",
    "        page += 1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to save results from page  1\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  1\n",
      "Clicking to next page...\n",
      "About to save results from page  2\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  2\n",
      "Clicking to next page...\n",
      "About to save results from page  3\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  3\n",
      "Clicking to next page...\n",
      "About to save results from page  4\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Could not extract info from multi-unit listing. Got Exception:  UNEXPECTED square footage: \n",
      "square feet \n",
      "\n",
      "\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "WARNING, first <p> of description section has attrs for url:  https://www.apartments.com/park-circle-village-north-charleston-sc/d544qxj/\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  4\n",
      "Clicking to next page...\n",
      "About to save results from page  5\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Could not extract info from multi-unit listing. Got Exception:  UNEXPECTED square footage: \n",
      "square feet \n",
      "\n",
      "\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  5\n",
      "Clicking to next page...\n",
      "About to save results from page  6\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "WARNING, first <p> of description section has attrs for url:  https://www.apartments.com/the-sullivan-1605-mount-pleasant-sc/hfe1jz2/\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  6\n",
      "Clicking to next page...\n",
      "About to save results from page  7\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  7\n",
      "Clicking to next page...\n",
      "About to save results from page  8\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  8\n",
      "Clicking to next page...\n",
      "About to save results from page  9\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "WARNING, first <p> of description section has attrs for url:  https://www.apartments.com/507-stinson-dr-charleston-sc-unit-c-4/xp7vv9p/\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Missing descriptionSection\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "WARNING, first <p> of description section has attrs for url:  https://www.apartments.com/21-george-st-charleston-sc-unit-410/lmxl6nd/\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  9\n",
      "Clicking to next page...\n",
      "About to save results from page  10\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  10\n",
      "Clicking to next page...\n",
      "About to save results from page  11\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  11\n",
      "Clicking to next page...\n",
      "About to save results from page  12\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  12\n",
      "Clicking to next page...\n",
      "About to save results from page  13\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  13\n",
      "Clicking to next page...\n",
      "About to save results from page  14\n",
      "Saved 1'st result.\n",
      "WARNING, first <p> of description section has attrs for url:  https://www.apartments.com/18-reid-st-charleston-sc/f9w92cr/\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "WARNING, first <p> of description section has attrs for url:  https://www.apartments.com/2244-ashley-crossing-dr-charleston-sc-unit-514/f3l73wv/\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  14\n",
      "Clicking to next page...\n",
      "About to save results from page  15\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  15\n",
      "Clicking to next page...\n",
      "About to save results from page  16\n",
      "Saved 1'st result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  16\n",
      "Clicking to next page...\n",
      "About to save results from page  17\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  17\n",
      "Clicking to next page...\n",
      "About to save results from page  18\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  18\n",
      "Clicking to next page...\n",
      "About to save results from page  19\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  19\n",
      "Clicking to next page...\n",
      "About to save results from page  20\n",
      "Saved 1'st result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 2'nd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 3'rd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 17'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  20\n",
      "Clicking to next page...\n",
      "About to save results from page  21\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 23'rd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 24'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  21\n",
      "Clicking to next page...\n",
      "About to save results from page  22\n",
      "Saved 1'st result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 2'nd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  22\n",
      "Clicking to next page...\n",
      "About to save results from page  23\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 4'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Saved 20'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "Saved 23'rd result.\n",
      "Saved 24'th result.\n",
      "Saved 25'th result.\n",
      "count:  25\n",
      "number of links:  25\n",
      "Finished saving page  23\n",
      "Clicking to next page...\n",
      "About to save results from page  24\n",
      "Saved 1'st result.\n",
      "Saved 2'nd result.\n",
      "Saved 3'rd result.\n",
      "Saved 4'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 5'th result.\n",
      "Saved 6'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 7'th result.\n",
      "Saved 8'th result.\n",
      "Saved 9'th result.\n",
      "Saved 10'th result.\n",
      "Saved 11'st result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 12'nd result.\n",
      "Saved 13'rd result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 14'th result.\n",
      "Saved 15'th result.\n",
      "Saved 16'th result.\n",
      "Saved 17'th result.\n",
      "Saved 18'th result.\n",
      "Saved 19'th result.\n",
      "Could not find combined_amenities, but did find unique_amenities\n",
      "Saved 20'th result.\n",
      "Saved 21'st result.\n",
      "Saved 22'nd result.\n",
      "count:  22\n",
      "number of links:  22\n",
      "Finished saving page  24\n",
      "It's the last page!\n"
     ]
    }
   ],
   "source": [
    "apt_outfile = open(\"/home/bryce/Projects/Data_Science/Apt_Prices/apt_scraping_results.csv\", \"w\")\n",
    "addr_outfile = open(\"/home/bryce/Projects/Data_Science/Apt_Prices/addr_scraping_results.csv\", \"w\")\n",
    "\n",
    "save_all_results(driver, apt_outfile, addr_outfile)\n",
    "apt_outfile.close()\n",
    "addr_outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"/home/bryce/Projects/Data_Science/Apt_Prices/all-results.csv\", \"w\")\n",
    "\n",
    "save_all_results(driver, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open('/tmp/aptscom.csv', 'w')\n",
    "print(\"hi\")\n",
    "get_info_from_listing(driver, out_file)\n",
    "print(\"bye\")\n",
    "out_file.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
